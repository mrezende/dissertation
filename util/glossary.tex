\newglossaryentry{ml}
{
    name=aprendizagem de máquina,
    description={sistema ou programa que constrói um modelo preditivo a partir de dados de entrada \citep{glossary-ml}}
}

\newglossaryentry{modelo}
{
    name=modelo,
    description={Representação do que um sistema de \gls{ml} aprendeu a partir de dados de treinamento \citep{glossary-ml}}
}

\newglossaryentry{sof}
{
    name=Stack Overflow,
    description={Site de perguntas e respostas de programação. Endereço do site: \url{https://www.stackoverflow.com/}}
}

\newglossaryentry{git}
{
    name=git,
    description={git é um versionador de controle distribuído para rastrear alterações no código-fonte durante o desenvolvimento de software. Endereço do site: \url{https://git-scm.com/} \citep{wikipedia-git-2019}}
}

\newglossaryentry{github}
{
    name=GitHub,
    description={GitHub é uma plataforma de hospedagem de código-fonte com controle de versão usando o \gls{git}. Endereço do site: \url{https://www.github.com/}}
}

\newglossaryentry{representacao-distribuida}
{
    name=representação distribuída,
    description={Representação distribuída significa uma relação de muitos para muitos entre dois tipos de representações (por exemplo, conceitos e \gls{neuron}s) \citep{Hinton-distributed-representatons:1986}
    }
}

\newglossaryentry{skip-gram}
{
    name=\textit{skip-gram},
    description={\textit{Skip-gram} é uma técnica do \gls{word2vec} que mapeia uma palavra para um vetor contínuo através da predição das palavras do contexto a partir de uma palavra-alvo. Mais informações na Seção~\ref{sec:fundamentao-representacao-tokens-palavras}
    }
}

\newglossaryentry{one-hot-encoding}
{
    name=\textit{one-hot encoding},
    description={\textit{one-hot encoding} é um vetor esparso que contém:
    \begin{itemize}
        \item Um elemento cujo valor é definido como 1
        \item O restante dos elementos tem o valor definido como 0
    \end{itemize}
    \textit{One-hot enconding} normalmente é utilizado para representar palavras e ou atributos que contém uma quantidade finita de valores \citep{glossary-ml}
    }
}

\newglossaryentry{token}
{
    name=\textit{token},
    description={\textit{token} refere-se a palavra ou termo presente nas descrições e/ou trechos de código-fonte na tarefa de recuperação de trecho de código-fonte
    }
}

\newglossaryentry{max-pooling}
{
    name=\textit{max pooling},
    description={\textit{Max pooling} refere-se a uma camada que reduz a dimensionalidade de um vetor aplicando a função \textit{max}, que retorna o maior elemento do vetor
    }
}

\newglossaryentry{neuron}
{
    name=neurônio,
    description={Um neurônio é um nó numa rede neural, que tipicamente recebe múltiplos valores de entrada e gera um valor de resultado. O neurônio aplica uma função de ativação (transformação não-linear) na soma dos valores de entrada com seus respectivos pesos \citep{glossary-ml}}
}

\newglossaryentry{bag-of-words}
{
    name=bag of words,
    description={Vetor composto por palavras indiferente à ordem e permutação. Ver exemplo na Seção~\ref{sec:representacao-das-sentencas-fundamentacao-teorica}}
}

\newglossaryentry{mecanismo-atencao}{
name=mecanismo de atenção,
description={
    O mecanismo de atenção calcula a média ponderada dos elementos de um vetor e o principal objetivo dele é encontrar um peso para cada elemento. Ao aplicarmos o mecanismo em uma tarefa de tradução, por exemplo, a cada momento que uma palavra é traduzida, o mecanismo de atenção foca em partes diferentes da sentença, i.e., ele aprende a ''prestar atenção'' nas palavras mais relevantes \citep{Goodfellow-et-al-2016}
}}

\newglossaryentry{docstring}{
name=docstring,
description={
    Em programação, um \textit{docstring} é um texto especificado no código-fonte que é usado para documentar um trecho específico do código \cite{wikipedia-docstring-2019}
}}

\newglossaryentry{jupyter}{
name=Jupyter,
description={
    \textit{Jupyter Notebook} é uma ferramenta interativa que permite desevolver, executar e documentar código em uma aplicação web. O termo \textit{notebook} refere-se a um caderno de anotações, pois é possível desenvolver, salvar as saídas do programa e fazer anotações \cite{jupyter-2019}
}}

\newglossaryentry{colab}{
name=colab,
description={
    É uma ferramenta de pesquisa e ensino para aprendizagem de máquina. É um ambiente \Gls{jupyter} que não necessita configuração ou instalação \cite{colab-2019}
}}

\newglossaryentry{unif}{
name=unif,
description={
    Arquitetura de rede neural com mecanismo de atenção proposta por \cite{cambronero-deep-learning-code-search:2019} para a recuperação de trecho de código-fonte
}}

\newglossaryentry{xlnet}{
name=XLNet,
description={
    Arquitetura autoregressiva para compreensão de linguagem durante o pré-treinamento \citep{yang2019xlNet}
}}

\newglossaryentry{word2vec}{
name=word2vec,
description={
    Word2vec é uma técnica para representar palavras através de vetores de \gls{representacao-distribuida}. Mais informações na Seção~\ref{sec:fundamentao-representacao-tokens-palavras}
}}

\newglossaryentry{tensorflow}{
name=tensorflow,
description={
    Tensorflow é uma biblioteca aberta de aprendizagem de máquina aplicável a uma ampla variedade de tarefas \citep{wikipedia-tensorflow-2020}
}}

\newglossaryentry{keras}{
name=keras,
description={
    Keras é uma biblioteca aberta de redes neurais escrita em Python \citep{wikipedia-keras-2020}
}}




\newacronym{ide}{IDE}{Integrated Development Environment}

\newacronym{rnn}{RNN}{\textit{Recurrent Neural Network}}
\newacronym{lstm}{LSTM}{\textit{Long Short Term Memory}}
\newacronym{nlp}{NLP}{\textit{Natural Language Processing}}
\newacronym{vae}{VAE}{\textit{Variational AutoEncoder}}
\newacronym{mlp}{MLP}{\textit{Multilayer Perceptron}}
\newacronym{tf-idf}{TFIDF}{\textit{Term Frequency–Inverse Document
Frequency}}
\newacronym{cbow}{CBoW}{\textit{Continuous Bag-of-Words}}
\newacronym{sof-ab}{SO}{\textit{Stack Overflow}}
\newacronym{github-ab}{GH}{\textit{GitHub}}
\newacronym{cnn}{CNN}{\textit{Convolutional Neural Network}}
\newacronym{vem}{VEM}{\textit{Workshop on Software Visualization, Evolution and Maintenance}}
\newacronym{mrr}{MRR}{\textit{Mean Reciprocal Rank}}
\newacronym{vgpu}{vGPU}{\textit{Virtual Graphics Processing Unit}}
\newacronym{elmo}{ELMo}{\textit{Embeddings from Language Models}}
\newacronym{bert}{BERT}{\textit{Bidirection Encoder Representations from Transformers}}
\newacronym{squad}{SQuAD}{\textit{Stanford Question Answering Dataset}}
\newacronym{map}{MAP}{\textit{Mean Average Precision}}
\newacronym{ndcg}{NDCG}{\textit{Normalized Discounted Cumulative Gain}}
\newacronym{gpu}{GPU}{\textit{Graphics Processing Unit}}
\newacronym{cpu}{CPU}{\textit{Central Processing Unit}}
\newacronym{nce}{NCE}{\textit{Noise Contrastive Estimation}}











