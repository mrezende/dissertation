%% ------------------------------------------------------------------------- %%
\chapter{Conclusões}
\label{cap:conclusoes}


A recuperação de trecho de código-fonte consiste em recuperar um trecho de código a partir de um repositório de modo a atender as intenções de um usuário, descritas em linguagem natural. Para auxiliar a recuperação de trecho de código e criar uma busca semântica, apresentamos neste trabalho uma proposta que utiliza redes neurais convolucionais na aprendizagem de representação. Os resultados, conforme apontados no Capítulo~\ref{cap:resultados}, foram promissores. A nossa arquitetura \acrshort{cnn} conseguiu classificar os trechos de código relevantes entre as 3 primeiras posições, de um total de 50, em 78\% dos casos. Além disso, conseguimos um resultado 5\% superior à arquitetura proposta por \cite{cambronero-deep-learning-code-search:2019}, estado da arte.

Durante os nossos experimentos, verificamos que as redes convolucionais obtiveram um melhor desempenho através da extração de características latentes utilizando bi-grams, ao invés de combinar filtros convolucionais de diferentes tamanhos (ver Apêndice~\ref{ape:ajuste-hiper-parametros-cnn}). A dificuldade da arquitetura CNN em extrair correlações entre palavras muito distantes não foi um problema aparente, pois a nossa amostra é composta marjoritariamente por questões e trechos de código relativamente curtos, onde 75\% da questões tem 11 palavras e 75\% dos trechos de código tem no máximo 55 palavras. 


%------------------------------------------------------
\section{Considerações Finais} 
\label{sec:consideracoes-finais}

Acreditamos que a aprendizagem de representação, que mostrou-se essencial em diversas tarefas em NLP, como tradução, classificação de textos, seleção de respostas, é um caminho para a recuperação de trecho de código-fonte. Juntamente a isso, acreditamos que as amostras obtidas através de fóruns abertos de perguntas e respostas como o \Gls{sof} são de extrema importância, pois foram organizados e curados coletivamente pelos usuáios, tornando-se uma fonte preciosa de informações.

As estratégias de seleção de respostas em NLP mostraram-se promissoras na recuperação de trecho de código-fonte. Em nosso caso, utilizamos a estratégia cunhada por \cite{feng-2015} e \cite{tan-lstm-qa}, que faz uso da aprendizagem de representação através de redes neurais convolucionais. Outras estratégias de seleção de respostas em NLP devem ser avaliadas e poderão servir como ponto de partida para futuras pesquisas na criação de uma busca semântica de código-fonte.

Devemos ressaltar que os resultados obtidos são apenas um indicativo promitente do bom desempenho das redes convolucionais na recuperação de trecho de código-fonte. É necessário uma análise qualitativa dos resultados, além de novos experimentos e pesquisas para verificar a efetividade da técnica. Em nosso trabalho, utilizamos apenas 60.000 pares de questões e trechos de código-fonte durante o treinamento e 1.000 pares de questões e respostas anotadas manualmente para avaliação. Estudos futuros podem explorar o treinamento não-supervisionado utilizando a enorme quantidade de dados disponíveis no Stack Overflow\footnote{Consulta feita em 12 de Agosto de 2020 no BigQuery do Google, que permite consultar as questões e perguntas do Stack Overflow através de uma consulta SQL (select count(*) from `bigquery-public-data.stackoverflow.posts\_questions` where upper(tags) like '\%PYTHON\%';)}, que possui aproximadamente 1 milhão e 600 mil perguntas somente com a palavra-chave Python.



%------------------------------------------------------
\section{Sugestões para Pesquisas Futuras} 

Ao longo deste trabalho, fizemos alguns apontamentos sobre possíveis direções a serem seguidas em futuras pesquisas. Dentre elas, destacamos aqui duas importantes linhas:

\begin{itemize}
    \item O bom desempenho de estratégias já conhecidas em NLP na recuperação de trecho de código-fonte, torna-se um importante ponto de partida para futuras pesquisas. Os recentes avanços na aprendizagem de representação obtidos pelo \textit{transformer} devem ser explorados em futuros trabalhos. 
    \item Uma hipótese para o bom desempenho das redes convolucionais foi o tamanho das questões e trechos de código-fonte, formados majoritariamente por sentenças curtas. Trabalhos futuros podem investigar a relação do tamanho das sentenças e o desempenho das redes convolucionais.
    \item bigramas conseguiram inferir o contexto das perguntas. palavras importantes estao proximas uma das outras, facilitando a rede neural convolucional a selecionar o trecho de código correto. uma analise qualitativa faz-se necessario para verificar a distancia das palavras que permitem inferir o contexto de uma pergunta e de um trecho de código-fonte.
    \item Além disso, a arquitetura proposta por \cite{cambronero-deep-learning-code-search:2019} não relacionou as questões aos trechos de código-fonte, pois o vetor das questões foi obtido através da média dos vetores contínuos das palavras, enquanto o trecho de código-fonte foi obtido através do mecanismo de auto-atenção global. Um possível caminho para trabalho futuro é utilizar um mecanismo de atenção que associe as palavras presentes nas questões aos trechos de código-fonte, explorando a correlação entre eles.
    \item Acreditamos que para problemas com sentenças longas, um possível caminho é o uso de redes neurais recorrentes ou \textit{transformers}, que mostraram bons resultados em processamento de linguagem natural \citep{devlin-etal-2019-bert}. 
    \item  A transferência de aprendizagem, que obteve ótimos resultados em diversas áreas como reconhecimento de fala, tradução e classificação de texto \citep{devlin-etal-2019-bert}, deve ser analisada por futuras pesquisas correlatas à busca semântica de código-fonte.
    \item O encapsulamento de modelos em uma ferramenta e a sua avaliação por usuários na prática.
\end{itemize}

Acreditamos que essas sugestões irão permear os futuros trabalhos na área de recuperação de trecho de código-fonte. 