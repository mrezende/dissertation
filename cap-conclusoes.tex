%% ------------------------------------------------------------------------- %%
\chapter{Conclusões}
\label{cap:conclusoes}


A recuperação de trecho de código-fonte consiste em recuperar um trecho de código a partir de um repositório de modo a atender as intenções de um usuário, descritas em linguagem natural. Para auxiliar a recuperação de trecho de código e criar uma busca semântica, apresentamos neste trabalho uma proposta que utiliza redes neurais convolucionais na aprendizagem de representação. Os resultados, conforme apontados no Capítulo~\ref{cap:resultados}, foram promissores. A nossa arquitetura \acrshort{cnn} conseguiu classificar os trechos de código relevantes entre as 3 primeiras posições, de um total de 50, em 78\% dos casos. Além disso, conseguimos um resultado 5\% superior à arquitetura proposta por \cite{cambronero-deep-learning-code-search:2019}, estado da arte.

Durante os nossos experimentos, verificamos que as redes convolucionais obtiveram um melhor desempenho através da extração de características latentes utilizando bi-grams, ao invés de combinar filtros convolucionais de diferentes tamanhos (ver Apêndice~\ref{ape:ajuste-hiper-parametros-cnn}). A dificuldade da arquitetura CNN em extrair correlações entre palavras muito distantes não foi um problema aparente, pois a nossa amostra é composta marjoritariamente por questões e trechos de código relativamente curtos, onde 75\% da questões tem 11 palavras e 75\% dos trechos de código tem no máximo 55 palavras. 


%------------------------------------------------------
\section{Considerações Finais} 
\label{sec:consideracoes-finais}

Acreditamos que a aprendizagem de representação, que mostrou-se essencial em diversas tarefas em NLP, como tradução, classificação de textos, seleção de respostas, é um caminho para a recuperação de trecho de código-fonte. Juntamente a isso, acreditamos que as amostras obtidas através de fóruns abertos de perguntas e respostas como o \Gls{sof} são de extrema importância, pois foram organizados e curados coletivamente pelos usuáios, tornando-se uma fonte preciosa de informações.

As estratégias de seleção de respostas em NLP mostraram-se promissoras na recuperação de trecho de código-fonte. Em nosso caso, utilizamos a estratégia cunhada por \cite{feng-2015} e \cite{tan-lstm-qa}, que faz uso da aprendizagem de representação através de redes neurais convolucionais. Outras estratégias de seleção de respostas em NLP devem ser avaliadas e poderão servir como ponto de partida para futuras pesquisas na criação de uma busca semântica de código-fonte.

Devemos ressaltar que os resultados obtidos são apenas um indicativo promitente do bom desempenho das redes convolucionais na recuperação de trecho de código-fonte. É necessário uma análise qualitativa dos resultados, além de novos experimentos e pesquisas para verificar a efetividade da técnica. Em nosso trabalho, utilizamos apenas 60.000 pares de questões e trechos de código-fonte durante o treinamento e 1000 pares de questões e respostas anotadas manualmente para avaliação. Estudos futuros podem explorar o treinamento não-supervisionado na construção de um modelo de linguagem para código-fonte, utilizando a enorme quantidade de dados disponíveis no Stack Overflow\footnote{Consulta feita em 12 de Agosto de 2020 no BigQuery do Google, que permite consultar as questões e perguntas do Stack Overflow através de uma consulta SQL (select count(*) from `bigquery-public-data.stackoverflow.posts\_questions` where upper(tags) like '\%PYTHON\%';)}, que possui aproximadamente 1 milhão e 600 mil perguntas somente com a palavra-chave Python.



%------------------------------------------------------
\section{Sugestões para Pesquisas Futuras} 

Ao longo deste trabalho, fizemos alguns apontamentos sobre possíveis direções a serem seguidas em futuras pesquisas. Dentre elas, destacamos aqui duas importantes linhas:

\begin{itemize}
    \item O bom desempenho de estratégias já conhecidas em NLP na recuperação de trecho de código-fonte torna-se um importante ponto de partida para futuras pesquisas. Acreditamos que os recentes avanços na aprendizagem de representação obtidas pelo \textit{transformers}, devem ser explorados em futuros trabalhos. 
    \item  A transferência de aprendizagem, que é uma realidade em NLP, e obteve ótimos resultados em diversas áreas como reconhecimento de fala, tradução e classificação de texto \cite{devlin-etal-2019-bert}, deve ser analisada e sua eficácia verificada na criação de uma busca semântica de código-fonte em futuras pesquisas.
\end{itemize}

Acreditamos que essas sugestões irão permear os futuros trabalhos na área de recuperação de trecho de código-fonte. 