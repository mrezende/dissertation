%% ------------------------------------------------------------------------- %%
\chapter{Introdução}
\label{cap:introducao}


Recuperação de trecho de código-fonte ou \textit{code retrieval} consiste em recuperar um trecho de código-fonte a partir de um repositório, de modo a atender as intenções do desenvolvedor, descritas em linguagem natural. A capacidade de recuperar trechos de código relevantes é uma importante ferramenta de produtividade. Sites como o Stack Overflow tornaram-se muito populares nos últimos anos devido a facilidade em buscar trechos de código-fonte a partir das questões expressas pelos usuários em linguagem natural \citep{cambronero-deep-learning-code-search:2019}. 

A busca por trecho de código em repositórios públicos tem sido um desafio. Atualmente, o site do Github, que hospeda milhares de projetos de código-aberto, não possui um mecanismo de pesquisa que
seja capaz de recuperar um trecho de código-fonte relevante a partir dos termos utilizados no campo de busca \citep{cambronero-deep-learning-code-search:2019}. Isto não é somente um desafio para repositórios públicos, mas para repositórios privados também. Os repositórios privados adicionam um desafio a mais, já que os desenvolvedores, muitas vezes, não podem se basear em trechos de código encontrados no Google ou Stack Overflow, pois eles podem não atender aos requisitos específicos da organização de API e uso de bibliotecas \citep{cambronero-deep-learning-code-search:2019}.

Conforme \cite{cambronero-deep-learning-code-search:2019}, muitos trabalhos tem sido feitos na academia e indústria em direção a uma busca mais avançada de código-fonte \citep{Gu-deep-code-search:2018, yao-2018, iyer-etal-2016-summarizing, Allamanis-bimodal-source-code-natural-language:2015, Chen-bi-variational-autoencoder:2018, Sachdev-neural-code-search:2018, cambronero-deep-learning-code-search:2019}. E um ponto em comum nestes trabalhos é o uso de \textit{deep learning}. Tanto que \cite{cambronero-deep-learning-code-search:2019} cunharam o termo \textit{neural code search}, i.e., busca de código-fonte através do uso de redes neurais. 

A principal abordagem utilizada nestes trabalhos é encontrar um \gls{modelo} que seja capaz de correlacionar os trechos de código as intenções do usuário. Uma técnica comumente utilizada é a \textit{joint embedding} ou agrupamento de representações distribuídas. Esta técnica mapeia dados de diferentes distribuições, modalidades para um mesmo espaço vetorial, de tal forma que conceitos similares ocupem regiões próximas neste espaço. Técnica bastante utilizada para associar textos e imagens, traduções e até mesmo problema de perguntas e respostas e recomendações \citep{lai-etal-2018-review, Zhang:2019:deep-learning-recommender-survey}.

A representação dos dados heterogêneos na técnica joint embedding tem um papel importante. Uma boa representação deve ser capaz de auxiliar na aprendizagem de uma tarefa
posterior \citep{Goodfellow-et-al-2016:representation-learning}. No nosso caso, uma boa representação das intenções e dos trechos de código-fonte deve ser capaz de ajudar a encontrar um modelo que seja capaz de correcioná-los. Além disso, uma boa representação pode ser útil para dados que seguem uma outra distribuição. Uma representação de trechos de código-fonte que foram coletadas de um site de dúvidas de programação podem ser utilizadas para encontrar trechos de código-fonte similares em repositórios de código aberto.

A proposta deste trabalho é verificar o uso das redes convolucionais na aprendizagem de representação. Dado que as redes convolucionais apresentaram um bom desempenho em diversos problema NLP, atingindo resultados competitivos em relação a outras arquiteturas como RNN \citep{tom-young:trends-deep-learning-nlp}, queremos avaliá-las na recuperação de trecho de código-fonte. Mais especificamente, pretendemos avaliar se elas auxiliam na obtenção de um modelo capaz de correlacionar os trechos de código-fonte as intenções do desenvolvedor. 

Um ponto importante a ressaltar é que ao optarmos por uma arquitetura CNN, estamos levando em consideração as suas características e limitações inerentes. Enquanto o RNN é capaz de fazer associações entre palavras muito distantes em um texto, o CNN prioriza interações locais. Ele tem dificuldades para extrair dependências de palavras muito distantes. E outro ponto é que o CNN é sensível a permutação, ele não é capaz de memorizar a localização exata de uma palavra em um texto \citep{Goodfellow-et-al-2016:convolutional-networks, tom-young:trends-deep-learning-nlp}.

A partir destas considerações, as perguntas que este trabalho pretende responder são:

\begin{itemize}
    \item Aprendizagem de representação através de uma arquitetura CNN auxilia na recuperação de trecho de código-fonte?
    
    \item Será que o CNN é capaz de extrair as características latentes e mais importantes de modo a facilitar o modelo a encontrar uma correlação entre os trechos de código-fonte e as intenções expressas em linguagem natural?
\end{itemize}

Indiretamente, dado que o CNN prioriza interações locais, estaremos respondendo também a seguinte pergunta:
\begin{itemize}
        \item As interações locais auxiliam na aproximação das intenções aos trechos de código-fonte?
\end{itemize}

Para respondê-las, avaliaremos um modelo que busca aproximar as intenções aos trechos de código-fonte. Para isto, o modelo vai ser estimulado a aproximar as suas representações. Estas representações serão obtidas a partir da nossa arquitetura CNN. A avaliação final do modelo será feita em um conjunto de dados composto por pares de questões e trechos de código-fonte coletados do site Stack Overflow. 


%% ------------------------------------------------------------------------- %%
\section{Considerações Preliminares}
\label{sec:consideracoes_preliminares}

O foco deste trabalho é a recuperação de trecho de código-fonte. Diferentemente dos trabalhos de \cite{iyer-etal-2016-summarizing} e \cite{Allamanis-bimodal-source-code-natural-language:2015} que abordaram também o problema de sumarização de código-fonte ou \textit{code summarization}. Para podermos avaliar a nossa arquitetura, iremos compará-la com outras arquiteturas de referência e com a arquitetura proposta por \cite{cambronero-deep-learning-code-search:2019} que é o estado da arte atualmente. Em relação aos dados, a base de dados disponibilizada por \cite{yao-2018} contém pares de questões e trechos de código-fonte em Python e SQL. A princípio, utilizaremos apenas os pares de perguntas e código-fonte em Python.


%% ------------------------------------------------------------------------- %%
\section{Objetivos}
\label{sec:objetivo}

O objetivo principal deste trabalho é propor uma nova abordagem para a recuperação de trecho de código-fonte. Queremos avaliar se o uso de redes convolucionais auxiliam na obtenção de um modelo que seja capaz de aproximar os trechos de código-fonte as intenções do desenvolvedor.

%% ------------------------------------------------------------------------- %%
\section{Contribuições}
\label{sec:contribucoes}

Dentre as contribuições deste trabalho estão:

\begin{itemize}
\item Proposta de uma nova abordagem para a recuperação de trecho de código-fonte;
\item Avaliação de uma nova arquitetura;
\item Avaliação do modelo utilizando uma nova base de dados disponibilizada por \cite{yao-2018};
\item Disponibilização do código-fonte, desde o pré-processamento até a avaliação final, em um repositório público;
\item Publicação dos resultados através de um artigo científico
\end{itemize}

%% ------------------------------------------------------------------------- %%
\section{Organização do Trabalho}
\label{sec:organizacao_trabalho}

No Capítulo~\ref{cap:fundamentacao-teorica}, apresentamos os conceitos e trabalhos relacionados a recuperação de trecho de código-fonte. No Capítulo~\ref{cap:abordagem}, apresentamos a nossa abordagem para o item de pesquisa proposto. No Capítulo~\ref{cap:resultados-preliminares}, exibimos os resultados preliminares da arquitetura proposta utilizando os dados de \cite{yao-2018}. Já no Capítulo~\ref{cap:cronograma} temos os próximos passos e o cronograma até a entrega do trabalho.