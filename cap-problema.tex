%% ------------------------------------------------------------------------- %%
\chapter{Abordagem}
\label{cap:abordagem}


Conforme citado no capítulo~\ref{cap:trabalhos-relacionados}, uma técnica muito utilizada para o problema de \textit{code retrieval} é o \textit{joint embedding}. Para utilizar esta técnica de \textit{joint embedding}, três fatores devem ser levados em consideração:

\begin{itemize}
    \item Representação de cada palavra de uma sentença ou trecho de código-fonte
    \item Representação da sentença e do trecho de código-fonte
    \item Função objetivo do modelo
\end{itemize}

\section{Representação de cada palavra de uma sentença ou trecho de código-fonte}
\label{sec:abordagem-representacao-token}

As questões e os trechos de código-fonte são compostas por palavras, pontuações, separadores e caracteres de símbolos e operadores matemáticos. Para as questões, que são descritas em linguagem natural, iremos representá-las como um vetor formado por uma sequência de palavaras removendo os caracteres de acento e pontuação.

No caso do código-fonte, iremos partir da  mesma hipótese que utilizamos no artigo \cite{marcelo-vem-2019} apresentado no \acrfull{vem}. Esta hipótese foi levantada por \cite{Allamanis:2018:SML} e diz que software é uma forma de comunicação humana e tem propriedades estatísticas similares a corpora de linguagem natural. A partir disto, iremos aplicar os mesmos procedimentos adotados para as questões aos trechos de código-fonte. Os trechos de código-fonte terão as pontuações e caracteres especiais removidos e serão tratados como uma sequência de palavras.

No nosso caso, tanto as questões e os trechos de código-fonte serão representados por um vetor formado por uma sequência de palavras. E para cada palavra no vetor, devemos definir uma representação.

De acordo com \cite{Goodfellow-et-al-2016:representation-learning}, as redes neurais generalizam bem quando as palavras são representadas através de vetores de representação distribuída. E conforme o próprio \cite{Goodfellow-et-al-2016:representation-learning}, uma boa representação deve auxiliar na aprendizagem de uma tarefa posterior. No nosso caso, as representações devem auxiliar a tarefa de aprender a encontrar uma correlação entre as questões e os trechos de código-fonte mais relevantes.

Neste trabalho, cada palavra será representada através de um vetor de representação distribuída. Para mapear as palavras para vetores de representação distribuída, utilizaremos inicialmente o algoritmo não-supervisionado \textit{word2vec}. Utilizaremos o \textit{word2vec} com \textit{skip-gram}. O \textit{skip-gram} prediz as palavras do contexto a partir de uma palavra alvo. Diferente do CBoW que prediz a palavra alvo a partir das palavras do contexto. A complexidade do algoritmo \textit{skip-gram} é O(n), enquanto CBoW é exponencial \todo{encontrar referencia complexity function}. 

O \textit{word2vec} irá mapear cada palavra para um espaço vetorial $\mathbb{R}^{d}$. Seja $\mathbb{Q}$ o conjunto de palavras das questões, e $\mathbb{C}$ o conjunto de palavras presentes nos trechos de código-fonte. Para cada palavra ${q} \in \mathbb{Q}$ e ${c} \in \mathbb{C}$, teremos:

\begin{equation}
    f: {q} \rightarrow t_{q}, t_{q} \in \mathbb{R}^{d}
\end{equation}

\begin{equation}
    g: {c} \rightarrow t_{c}, t_{c} \in \mathbb{R}^{d}
\end{equation}
Onde $f$ e $g$ são o \textit{word2vec} com o algoritmo \textit{skip-gram}. $f$ e $g$ irão mapear cada palavra pertencente a um vocabulário a uma matriz distinta $\bm{T_{q}}$ e $\bm{T_{c}}$.
Teremos duas matrizes: $\bm{T}_{q}^{|\mathbb{Q}| X d}$ e outra $\bm{T}_{c}^{|\mathbb{C}| X d}$, onde $|\mathbb{Q}|$ e $|\mathbb{C}|$ são o tamanho do vocabulário das questões e trechos de código-fonte, respectivamente. E $d$ é a dimensão do vetor de representação distribuída.

\section{Representação da sentença e do trecho de código-fonte}

Com cada palavra representada por um vetor de representação distribuída, o próximo passo é combiná-los para obter uma representação para a questão e o trecho de código-fonte. A partir de agora, cada questão ou trecho de código-fonte será representada por um vetor $\bm{x}$, onde $x = \{ \bm{x}(1), \bm{x}(2), . . ., \bm{x}(n) \}$, tal que $\bm{x}(w) \in \mathbb{R}^{d}$ e $w$ é uma palavra presente no vocabulário da questão ou trecho de código-fonte \citep{cambronero-deep-learning-code-search:2019}. 

Lembrando que neste trabalho, temos duas matrizes de representação distribuída, $\bm{T}_{q}$ e $\bm{T}_{c}$. Para fins de simplificação, quando utilizarmos $\bm{x}$, $\bm{x}$ pode ser $\bm{x} = \{ t_{q}(1), t_{q}(2), . . ., t_{q}(n)\}$, $t_{q}(i) \in \bm{T}_{q}, 1 \leq i \leq n$ ou pode ser $\bm{x} = \{ t_{c}(1), t_{c}(2), . . ., t_{c}(n)\}$, $t_{c}(i) \in \bm{T}_{c}, 1 \leq i \leq n$.


Iremos avaliar duas formas de representar as questões e trechos de código-fonte. Uma abordagem é utilizando uma rede neural recorrente bi-LSTM com uma camada CNN posterior. E a outra abordagem é uma rede CNN apenas.

\subsection{Representação através de bi-LSTM com CNN}
\label{sec:representation-bi-lstm-cnn}
\subsection{bi-LSTM}
\label{sec:representation-bi-lstm}
Utilizando o LSTM, a partir de um vetor $\bm{x} = \{ \bm{x}(1), \bm{x}(2), . . ., \bm{x}(n) \}$, onde $\bm{x}(t)$ é um vetor de representação de dimensão $d$. O valor do vetor de \textit{hidden} $\bm{h}(t)$ (tamanho $H$) na iteração $t$ é \citep{tan-lstm-qa}:

\begin{equation}
    i_{t} = \sigma(\bm{W}_{i}\bm{x}(t) + \bm{U}_{i}\bm{h}(t - 1) + \bm{b}_{i})
\end{equation}
\begin{equation}
    f_{t} = \sigma(\bm{W}_{f}\bm{x}(t) + \bm{U}_{f}\bm{h}(t - 1) + \bm{b}_{f})
\end{equation}
\begin{equation}
    o_{t} = \sigma(\bm{W}_{o}\bm{x}(t) + \bm{U}_{o}\bm{h}(t - 1) + \bm{b}_{o})
\end{equation}
\begin{equation}
    \bar{C}_{t} = tanh(\bm{W}_{c}\bm{x}(t) + \bm{U}_{c}\bm{h}(t - 1) + \bm{b}_{c})
\end{equation}
\begin{equation}
    C_{t} = i_{t} * \bar{C}_t + f_{t} * C_{t - 1}
\end{equation}
\begin{equation}
    \bm{h}_{t} = o_{t} * tanh(C_{t})
\end{equation}

No caso do bi-LSTM, teremos duas redes LSTM, uma rede que lê o vetor $\overrightarrow{\bm{x}}$ na ordem da primeira para a última palavra, $\bm{x}(1), \bm{x}(2), . . ., \bm{x}(n)$. E a outra rede LSTM vai ler na ordem inversa, $\overleftarrow{\bm{x}}$, $\bm{x}(n), \bm{x}(n - 1), . . ., \bm{x}(1)$. Teremos dois vetores \textit{hidden}, $\overrightarrow{\bm{h}_{t}}$ e $\overleftarrow{\bm{h}_{t}}$. Para cada iteração $t$, o vetor de resultado é a concatenação dos dois vetores \textit{hidden}: $\bm{h}_{t} = \overrightarrow{\bm{h}_{t}} || \overleftarrow{\bm{h}_{t}}$.

\subsubsection{CNN}
\label{sec:cnn}

Após obter os vetores \textit{hidden} das questões e trechos de código-fonte, eles são utilizados como entrada para um rede neural convolucional. 

Para cada janela de tamanho $m$ aplicado aos vetores \textit{hidden} da rede bi-LSTM, ie. 
$\bm{H}_{m}(t) = [\bm{h}(t), \bm{h}(t + 1), · · · , \bm{h}(t + m − 1)]$, onde $t$ é a iteração, o filtro convolucional $\bm{F}  = [\bm{F}(0),· · ·, \bm{F}(m − 1)]$ irá gerar o seguinte valor \citep{tan-lstm-qa}:

\begin{equation}
    o_{F}(t) = tanh \left[\left(\sum_{i=0}^{m - 1} \bm{h}(t-1)^{T}\bm{F}(i)\right) + b\right]
\end{equation}

onde $b$ é o \textit{bias} e $\bm{F}$ e $b$ são parâmetros do filtro.

Como as redes CNNs típicas, uma camada \textit{max-k pooling} é aplicada posteriormente a camada convolucional. Intuitivamente, queremos enfatizar os $k$ maiores valores para cada filtro convolucional. Através do \textit{k-max pooling}, os $k$ valores máximos serão mantidos para um filtro, o que indica um alto valor de que o filtro coincidiu com a entrada. \todo{rever esta frase}

A camada convolucional irá gerar vetores de resultado de dimensão $N$, utilizando $N$ filtros paralelos, com diferentes parâmetros de inicialização. Ao final, teremos dois vetores de resultado de dimensão $kN$ para as questões e os trechos de código-fonte respectivamente. Neste trabalho, utilizaremos inicialmente o valor k = 1, seguindo a recomendação de \cite{tan-lstm-qa}. De acordo com \cite{tan-lstm-qa}, a intuição da combinação dos vetores \textit{hidden} do bi-LSTM através do CNN é, ao invés de considerar a informação léxica de cada \textit{token}, o CNN enfatiza certas partes do trecho de código-fonte, de forma que o bi-LSTM com CNN seja mais efetivo na diferenciação das respostas observadas como corretas das incorretas.


\subsection{Representação através do CNN}
\label{sec:representation-cnn}

Para verificar o desempenho do CNN isoladamente, iremos criar uma representação para as questões e trechos de código-fonte somente com uma camada CNN.

Diferente da arquitetura anterior, o vetor $\bm{x} = \{ \bm{x}(1), \bm{x}(2), . . ., \bm{x}(n) \}$, onde $\bm{x}(t)$ é um vetor de representação de dimensão $d$, servirá de entrada para uma camada \textit{hidden} ao invés de uma camada bi-LSTM. A camada \textit{hidden} é para transformar o vetor de representação distribuída em um vetor de entrada para o CNN \citep{tan-lstm-qa}.

A camada \textit{hidden} contém a seguinte função:

\begin{equation}
z = tanh(\bm{W}x + b)
\end{equation}

Onde $\bm{W}$ é a matriz de pesos e $\bm{b}$ é o vetor de \textit{bias}.

Neste caso, $z$ servirá de entrada a rede CNN. Mais detalhes sobre os cálculos, ver a subseção anterior CNN~\ref{sec:cnn}.

\section{Função objetivo}

Tanto o bi-LSTM com CNN e o CNN geram representações para as questões e os trechos de código-fonte. O intuito é encontrar um modelo que correlacione as questões as respostas em um mesmo espaço vetorial. Neste trabalho adotaremos a mesma abordagem utilizada por \cite{feng-2015}, o método \textit{pairwise}. O método \textit{pairwise} consiste em treinar o modelo para classificar as respostas corretas com uma pontuação maior do que as incorretas. Formalmente, o modelo será treinado do seguinte modo:

Seja $\mathbb{Q}$ um conjunto de questões e $\mathbb{C}$ um conjunto dos trechos de código-fonte. $\mathbb{Q}$ e $\mathbb{C}$ compõem o conjunto de dados de treinamento.

Dado uma tripla $<q, c^{+}, c^{-}>$, onde $c^{+}$ é uma resposta correta observada para a questão $q \in \mathbb{Q}$. E $c^{-}$ é uma resposta incorreta. A função de custo \textit{hinge} é definida como:

\begin{equation}
J = max(0, m - h_{\theta}(q, c^{+}) + h_{\theta}(q, c^{-}))
\end{equation}

Onde $m$ é uma margem e $h_{\theta}$ é uma função de similaridade, e.g., \textit{cosine}. O objetivo é minimizar a função $J$. Para isto, o modelo vai ser incentivado a satisfazer a seguinte condição: $h_{\theta}(q, c^{+}) - h_{\theta}(q, c^{-}) \geq m$. Quer dizer, a função \textit{hinge} induz o modelo a classificar as respostas corretas com uma pontuação maior do que as incorretas por uma certa margem $m$.

